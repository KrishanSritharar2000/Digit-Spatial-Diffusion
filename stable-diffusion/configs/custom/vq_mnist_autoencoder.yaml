model:
    base_learning_rate: 4.5e-6
    target: ldm.models.autoencoder.VQModelInterface
    params:
        lossconfig:
            target: ldm.modules.losses.VQLPIPSWithDiscriminator
            params:
                disc_start: 50001
                disc_weight: 0.5
                disc_in_channels: 3

        embed_dim: 3
        n_embed: 8192
        monitor: val/rec_loss
        ddconfig:
          double_z: false
          z_channels: 3
          resolution: 128
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult: [1, 2, 4]
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0

data:
    target: main.DataModuleFromConfig
    params:
        batch_size: 8
        wrap: True
        train:
            target: custom.data.mnist_dataset.MNISTTrain
            params:
                size: 128
        validation:
            target: custom.data.mnist_dataset.MNISTValidation
            params:
                size: 128
        

lightning:
    callbacks:
        image_logger:
            target: main.ImageLogger
            params:
                batch_frequency: 1000
                max_images: 8
                increase_log_steps: True

    trainer:
        benchmark: True
        accumulate_grad_batches: 2
